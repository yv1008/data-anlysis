{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8c8765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"College.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a6b7fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>No</td>\n",
       "      <td>2197</td>\n",
       "      <td>1515</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1959</td>\n",
       "      <td>1805</td>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2097</td>\n",
       "      <td>1915</td>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Yes</td>\n",
       "      <td>10705</td>\n",
       "      <td>2453</td>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2989</td>\n",
       "      <td>1855</td>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Private   Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0       Yes   1660    1232     721         23         52         2885   \n",
       "1       Yes   2186    1924     512         16         29         2683   \n",
       "2       Yes   1428    1097     336         22         50         1036   \n",
       "3       Yes    417     349     137         60         89          510   \n",
       "4       Yes    193     146      55         16         44          249   \n",
       "..      ...    ...     ...     ...        ...        ...          ...   \n",
       "772      No   2197    1515     543          4         26         3089   \n",
       "773     Yes   1959    1805     695         24         47         2849   \n",
       "774     Yes   2097    1915     695         34         61         2793   \n",
       "775     Yes  10705    2453    1317         95         99         5217   \n",
       "776     Yes   2989    1855     691         28         63         2988   \n",
       "\n",
       "     P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0            537      7440        3300    450      2200   70        78   \n",
       "1           1227     12280        6450    750      1500   29        30   \n",
       "2             99     11250        3750    400      1165   53        66   \n",
       "3             63     12960        5450    450       875   92        97   \n",
       "4            869      7560        4120    800      1500   76        72   \n",
       "..           ...       ...         ...    ...       ...  ...       ...   \n",
       "772         2029      6797        3900    500      1200   60        60   \n",
       "773         1107     11520        4960    600      1250   73        75   \n",
       "774          166      6900        4200    617       781   67        75   \n",
       "775           83     19840        6510    630      2115   96        96   \n",
       "776         1726      4990        3560    500      1250   75        75   \n",
       "\n",
       "     S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0         18.1           12    7041         60  \n",
       "1         12.2           16   10527         56  \n",
       "2         12.9           30    8735         54  \n",
       "3          7.7           37   19016         59  \n",
       "4         11.9            2   10922         15  \n",
       "..         ...          ...     ...        ...  \n",
       "772       21.0           14    4469         40  \n",
       "773       13.3           31    9189         83  \n",
       "774       14.4           20    8323         49  \n",
       "775        5.8           49   40386         99  \n",
       "776       18.1           28    4509         99  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de792350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['Private'])\n",
    "data2 = df.drop(['Private'],axis = 'columns')\n",
    "data2['Private'] = label\n",
    "df = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7734252c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "      <th>Private</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>2197</td>\n",
       "      <td>1515</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>1959</td>\n",
       "      <td>1805</td>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>2097</td>\n",
       "      <td>1915</td>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>10705</td>\n",
       "      <td>2453</td>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2989</td>\n",
       "      <td>1855</td>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  P.Undergrad  \\\n",
       "0     1660    1232     721         23         52         2885          537   \n",
       "1     2186    1924     512         16         29         2683         1227   \n",
       "2     1428    1097     336         22         50         1036           99   \n",
       "3      417     349     137         60         89          510           63   \n",
       "4      193     146      55         16         44          249          869   \n",
       "..     ...     ...     ...        ...        ...          ...          ...   \n",
       "772   2197    1515     543          4         26         3089         2029   \n",
       "773   1959    1805     695         24         47         2849         1107   \n",
       "774   2097    1915     695         34         61         2793          166   \n",
       "775  10705    2453    1317         95         99         5217           83   \n",
       "776   2989    1855     691         28         63         2988         1726   \n",
       "\n",
       "     Outstate  Room.Board  Books  Personal  PhD  Terminal  S.F.Ratio  \\\n",
       "0        7440        3300    450      2200   70        78       18.1   \n",
       "1       12280        6450    750      1500   29        30       12.2   \n",
       "2       11250        3750    400      1165   53        66       12.9   \n",
       "3       12960        5450    450       875   92        97        7.7   \n",
       "4        7560        4120    800      1500   76        72       11.9   \n",
       "..        ...         ...    ...       ...  ...       ...        ...   \n",
       "772      6797        3900    500      1200   60        60       21.0   \n",
       "773     11520        4960    600      1250   73        75       13.3   \n",
       "774      6900        4200    617       781   67        75       14.4   \n",
       "775     19840        6510    630      2115   96        96        5.8   \n",
       "776      4990        3560    500      1250   75        75       18.1   \n",
       "\n",
       "     perc.alumni  Expend  Grad.Rate  Private  \n",
       "0             12    7041         60        1  \n",
       "1             16   10527         56        1  \n",
       "2             30    8735         54        1  \n",
       "3             37   19016         59        1  \n",
       "4              2   10922         15        1  \n",
       "..           ...     ...        ...      ...  \n",
       "772           14    4469         40        0  \n",
       "773           31    9189         83        1  \n",
       "774           20    8323         49        1  \n",
       "775           49   40386         99        1  \n",
       "776           28    4509         99        1  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50568484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43c0cb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Apps', 'Accept', 'Enroll', 'Top10perc', 'Top25perc', 'F.Undergrad',\n",
       "       'P.Undergrad', 'Outstate', 'Room.Board', 'Books', 'Personal', 'PhD',\n",
       "       'Terminal', 'S.F.Ratio', 'perc.alumni', 'Expend', 'Grad.Rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop(\"Private\",axis=1)\n",
    "y = df['Private']\n",
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "X = X.columns\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "230d3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[X]# taking the training data input\n",
    "train_y= train['Private']\n",
    "test_X= test[X] # taking test data inputs\n",
    "test_y =test['Private']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb1acb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9551282051282052\n"
     ]
    }
   ],
   "source": [
    "#RandomForest classifier\n",
    "model=RandomForestClassifier(n_estimators=100)# a simple random forest model\n",
    "model.fit(train_X,train_y)# now fit our model for traiing data\n",
    "prediction=model.predict(test_X)# predict for the test data\n",
    "#prediction will contain the predicted value by our model predicted values of diagnosis column for test inputs\n",
    "print(metrics.accuracy_score(prediction,test_y)) # to check the accuracy\n",
    "# here we will use accuracy measurement between our predicted value and our test output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41371648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuray: 0.9294871794871795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm    \t\t# To import the svm classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(train_X,train_y)\n",
    "#Predict Output\n",
    "predicted= model.predict(test_X)\n",
    "print(\"SVM accuray:\",accuracy_score(test_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a69f895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.938 (0.022)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot\n",
    "dataset = df\n",
    "data = dataset.values\n",
    "# separate into input and output columns\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# ensure inputs are floats and output is an integer label\n",
    "X = X.astype('float32')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "# define and configure the model\n",
    "model = svm.SVC(kernel='linear')()\n",
    "model.fit(train_X,train_y)\n",
    "#Predict Output\n",
    "predicted= model.predict(test_X)\n",
    "print(\"SVM accuray:\",accuracy_score(test_y, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24f3e338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.46881819e-01 -3.21205453e-01 -6.35089011e-02 ... -5.01910084e-01\n",
      "  -3.18251941e-01  6.12553050e-01]\n",
      " [-2.10884040e-01 -3.87029908e-02 -2.88584214e-01 ...  1.66109850e-01\n",
      "  -5.51261842e-01  6.12553050e-01]\n",
      " [-4.06865631e-01 -3.76317928e-01 -4.78121319e-01 ... -1.77289956e-01\n",
      "  -6.67766793e-01  6.12553050e-01]\n",
      " ...\n",
      " [-2.33895071e-01 -4.23771558e-02 -9.15087008e-02 ... -2.56241250e-01\n",
      "  -9.59029170e-01  6.12553050e-01]\n",
      " [ 1.99171118e+00  1.77256262e-01  5.78332661e-01 ...  5.88797079e+00\n",
      "   1.95359460e+00  6.12553050e-01]\n",
      " [-3.26765760e-03 -6.68715889e-02 -9.58163623e-02 ... -9.87115613e-01\n",
      "   1.95359460e+00  6.12553050e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kapil\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(df)\n",
    "print(scaled)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # only compute mean and std here\n",
    "X_test = scaler.transform(X_test)  # perform standardization by centering and scaling\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18953dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ........................kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ........................kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ........................kernel=rbf;, score=0.871 total time=   0.0s\n",
      "[CV 4/5] END ........................kernel=rbf;, score=0.968 total time=   0.0s\n",
      "[CV 5/5] END ........................kernel=rbf;, score=0.935 total time=   0.0s\n",
      "{'kernel': 'rbf'}\n",
      "SVC()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'kernel': ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dadc921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       173\n",
      "           1       0.72      1.00      0.84       449\n",
      "\n",
      "    accuracy                           0.72       622\n",
      "   macro avg       0.36      0.50      0.42       622\n",
      "weighted avg       0.52      0.72      0.61       622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kapil\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kapil\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kapil\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64954e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
